{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c697ad2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Note, to use this code, please follow the instuctions in \n",
    "# https://tts.readthedocs.io/en/latest/installation.html to install the TTS package\n",
    "\n",
    "import os\n",
    "import sys\n",
    "# pylint: disable=redefined-outer-name, unused-argument\n",
    "from pathlib import Path\n",
    "import TTS\n",
    "from TTS.utils.manage import ModelManager\n",
    "from TTS.utils.synthesizer import Synthesizer\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from os import path\n",
    "import pyaudio\n",
    "import sys\n",
    "import speech_recognition as sr\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM # Machine Translation\n",
    "import librosa\n",
    "from IPython.display import Audio\n",
    "from transformers import MarianTokenizer, MarianMTModel\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ccfec120",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def speechRecognition(AUDIO_FILE = 'untitled.wav',src = 'en',event = None):\n",
    "    r = sr.Recognizer()\n",
    "    with sr.AudioFile(AUDIO_FILE) as source:\n",
    "        audio = r.listen(source)\n",
    "        output = r.recognize_google(audio)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71fb44d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Machine Translation\n",
    "def machineTranslation(output, src = \"en\", trg = \"ja\"):\n",
    "    try:\n",
    "        model_name = f\"Helsinki-NLP/opus-tatoeba-{src}-{trg}\" # en-ja model\n",
    "        tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
    "    except:\n",
    "        model_name = f\"Helsinki-NLP/opus-mt-{src}-{trg}\" \n",
    "        tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
    "\n",
    "    model = MarianMTModel.from_pretrained(model_name)\n",
    "    \n",
    "    batch = tokenizer([output], return_tensors=\"pt\")\n",
    "    generated_ids = model.generate(**batch)\n",
    "    return tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "321be8d5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Using model: vits\n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:16000\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > log_func:np.log\n",
      " | > min_level_db:-100\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:20\n",
      " | > fft_size:1024\n",
      " | > power:1.5\n",
      " | > preemphasis:0.0\n",
      " | > griffin_lim_iters:60\n",
      " | > signal_norm:False\n",
      " | > symmetric_norm:True\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:None\n",
      " | > pitch_fmin:0.0\n",
      " | > pitch_fmax:640.0\n",
      " | > spec_gain:1.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:4.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:True\n",
      " | > trim_db:45\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:False\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:None\n",
      " | > base:2.718281828459045\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:16000\n",
      " | > resample:False\n",
      " | > num_mels:64\n",
      " | > log_func:np.log10\n",
      " | > min_level_db:-100\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:20\n",
      " | > fft_size:512\n",
      " | > power:1.5\n",
      " | > preemphasis:0.97\n",
      " | > griffin_lim_iters:60\n",
      " | > signal_norm:False\n",
      " | > symmetric_norm:False\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:8000.0\n",
      " | > pitch_fmin:0.0\n",
      " | > pitch_fmax:640.0\n",
      " | > spec_gain:20.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:4.0\n",
      " | > clip_norm:False\n",
      " | > do_trim_silence:False\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:True\n",
      " | > db_level:-27.0\n",
      " | > stats_path:None\n",
      " | > base:10\n",
      " | > hop_length:160\n",
      " | > win_length:400\n",
      " > initialization of language-embedding layers.\n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:16000\n",
      " | > resample:False\n",
      " | > num_mels:64\n",
      " | > log_func:np.log10\n",
      " | > min_level_db:-100\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:20\n",
      " | > fft_size:512\n",
      " | > power:1.5\n",
      " | > preemphasis:0.97\n",
      " | > griffin_lim_iters:60\n",
      " | > signal_norm:False\n",
      " | > symmetric_norm:False\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:8000.0\n",
      " | > pitch_fmin:0.0\n",
      " | > pitch_fmax:640.0\n",
      " | > spec_gain:20.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:4.0\n",
      " | > clip_norm:False\n",
      " | > do_trim_silence:False\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:True\n",
      " | > db_level:-27.0\n",
      " | > stats_path:None\n",
      " | > base:10\n",
      " | > hop_length:160\n",
      " | > win_length:400\n",
      " > Using Griffin-Lim as no vocoder model defined\n"
     ]
    }
   ],
   "source": [
    "# Create Synth\n",
    "\n",
    "model = 1\n",
    "\n",
    "if model == 1:\n",
    "    model_path = 'GermanModel/best_model_96618.pth'\n",
    "    config_path = 'GermanModel/config.json'\n",
    "    speakers_file_path = 'GermanModel/speakers.json'\n",
    "    language_ids_file_path = 'GermanModel/language_ids.json'\n",
    "else:\n",
    "    model_path = 'checkpoint_20000.pth'\n",
    "    config_path = 'config.json'\n",
    "    speakers_file_path = 'speakers.json'\n",
    "    language_ids_file_path = 'language_ids.json'\n",
    "    \n",
    "\n",
    "vocoder_path = None\n",
    "vocoder_config_path = None\n",
    "encoder_path = 'model_se.pth.tar'\n",
    "encoder_config_path = 'config_se.json'\n",
    "use_cuda = False\n",
    "\n",
    "synth = Synthesizer(\n",
    "        model_path,\n",
    "        config_path,\n",
    "        speakers_file_path,\n",
    "        language_ids_file_path,\n",
    "        vocoder_path,\n",
    "        vocoder_config_path,\n",
    "        encoder_path,\n",
    "        encoder_config_path,\n",
    "        use_cuda,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4533ef67",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Transliterator \n",
    "\n",
    "import pykakasi\n",
    "kks = pykakasi.kakasi()\n",
    "\n",
    "def transliterate(kks,item):\n",
    "    return \" \".join([item['hepburn'] for item in kks.convert(item)])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b4669a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def speechtranslate(wav = 'untitled.wav',synth = synth,src = 'en',trg = 'ja', text = None,refwav = None):\n",
    "    if text is None:\n",
    "        text = speechRecognition(wav,src)\n",
    "    print(text)\n",
    "\n",
    "    if src != trg:\n",
    "        text = machineTranslation(text,src,trg)\n",
    "\n",
    "    print(text)\n",
    "    if trg == 'ja': # transliterate japanese\n",
    "        kks = pykakasi.kakasi()\n",
    "        text = transliterate(kks,text)\n",
    "    if trg == 'fr':\n",
    "        trg = trg + '-' + trg\n",
    "    if trg == 'de':\n",
    "        trg = trg + '_' + trg\n",
    "    if refwav is None:\n",
    "        return synth.tts(text=text,speaker_wav=wav,language_name=trg)\n",
    "    else:\n",
    "        return synth.tts(text=text,speaker_wav=refwav,language_name=trg)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4ce1e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6baa8024",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " So she was considering in her own mind (as well as she could, for the hot day made her feel very sleepy and stupid), whether the pleasure of making a daisy-chain would be worth the trouble of getting up and picking the daisies, when suddenly a White Rabbit with pink eyes ran close by her. \n",
      "それで,彼女は自分の心で(また出来るほどに)考へた。 暑い日には、とても眠くて愚かな感じがした。 デージー・チャインを作る楽しみは、起き上ってダサイを拾うことに苦労する価値があるかどうか、と。 突然、ピンクの眼を持つ白のウサギが彼女の近くに走って来た。\n",
      " > Text splitted to sentences.\n",
      "['sorede, kanojo ha jibun no kokoro de ( mata dekiru hodoni) kangahe ta.', 'atsui nichi niha, totemo nemuku te oroka na kanji gashita.', 'deejii・chain wo tsukuru tanoshimi ha, okiatsu te dasai wo hirou kotoni kurou suru kachi gaarukadouka, to.', 'totsuzen, pinku no me wo motsu shiro no usagi ga kanojo no chikaku ni hashitsu te kita.']\n",
      "['<BLNK>', 'd', '<BLNK>', 'e', '<BLNK>', 'e', '<BLNK>', 'j', '<BLNK>', 'i', '<BLNK>', 'i', '<BLNK>', '・', '<BLNK>', 'c', '<BLNK>', 'h', '<BLNK>', 'a', '<BLNK>', 'i', '<BLNK>', 'n', '<BLNK>', ' ', '<BLNK>', 'w', '<BLNK>', 'o', '<BLNK>', ' ', '<BLNK>', 't', '<BLNK>', 's', '<BLNK>', 'u', '<BLNK>', 'k', '<BLNK>', 'u', '<BLNK>', 'r', '<BLNK>', 'u', '<BLNK>', ' ', '<BLNK>', 't', '<BLNK>', 'a', '<BLNK>', 'n', '<BLNK>', 'o', '<BLNK>', 's', '<BLNK>', 'h', '<BLNK>', 'i', '<BLNK>', 'm', '<BLNK>', 'i', '<BLNK>', ' ', '<BLNK>', 'h', '<BLNK>', 'a', '<BLNK>', ',', '<BLNK>', ' ', '<BLNK>', 'o', '<BLNK>', 'k', '<BLNK>', 'i', '<BLNK>', 'a', '<BLNK>', 't', '<BLNK>', 's', '<BLNK>', 'u', '<BLNK>', ' ', '<BLNK>', 't', '<BLNK>', 'e', '<BLNK>', ' ', '<BLNK>', 'd', '<BLNK>', 'a', '<BLNK>', 's', '<BLNK>', 'a', '<BLNK>', 'i', '<BLNK>', ' ', '<BLNK>', 'w', '<BLNK>', 'o', '<BLNK>', ' ', '<BLNK>', 'h', '<BLNK>', 'i', '<BLNK>', 'r', '<BLNK>', 'o', '<BLNK>', 'u', '<BLNK>', ' ', '<BLNK>', 'k', '<BLNK>', 'o', '<BLNK>', 't', '<BLNK>', 'o', '<BLNK>', 'n', '<BLNK>', 'i', '<BLNK>', ' ', '<BLNK>', 'k', '<BLNK>', 'u', '<BLNK>', 'r', '<BLNK>', 'o', '<BLNK>', 'u', '<BLNK>', ' ', '<BLNK>', 's', '<BLNK>', 'u', '<BLNK>', 'r', '<BLNK>', 'u', '<BLNK>', ' ', '<BLNK>', 'k', '<BLNK>', 'a', '<BLNK>', 'c', '<BLNK>', 'h', '<BLNK>', 'i', '<BLNK>', ' ', '<BLNK>', 'g', '<BLNK>', 'a', '<BLNK>', 'a', '<BLNK>', 'r', '<BLNK>', 'u', '<BLNK>', 'k', '<BLNK>', 'a', '<BLNK>', 'd', '<BLNK>', 'o', '<BLNK>', 'u', '<BLNK>', 'k', '<BLNK>', 'a', '<BLNK>', ',', '<BLNK>', ' ', '<BLNK>', 't', '<BLNK>', 'o', '<BLNK>', '.', '<BLNK>']\n",
      " [!] Character '・' not found in the vocabulary. Discarding it.\n",
      " > Processing time: 4.88018798828125\n",
      " > Real-time factor: 0.17981532749746684\n"
     ]
    }
   ],
   "source": [
    "audio = speechtranslate(wav = 'Gasby.wav',src = 'en',trg = 'ja', text = None ,refwav = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4298eaf0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "synth.save_wav(audio,'frtest.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a8f1eff5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b69f3e77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Text splitted to sentences.\n",
      "['soreha nazo no kotae da']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/supernova/.local/share/virtualenvs/DS340W_Project-lU6ifWGj/lib/python3.9/site-packages/torch/autocast_mode.py:162: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Processing time: 2.9315192699432373\n",
      " > Real-time factor: 1.0773683461753905\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9ccb33ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c458d45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8e62ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f945ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e353de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1671b39a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4348784",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5304d3bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a06c85a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5cfcc1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DS340W",
   "language": "python",
   "name": "ds340w"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
